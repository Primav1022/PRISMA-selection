#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨ Phi-3 è®ºæ–‡åˆ†æç³»ç»Ÿ
=====================================

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ 5_intelligent_with_phi3.py ä¸­çš„å„ä¸ªç»„ä»¶
æ¥åˆ†æè®ºæ–‡æ•°æ®å¹¶ç”Ÿæˆæ™ºèƒ½æ‘˜è¦ã€‚

"""

import pandas as pd
import os
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬çš„åˆ†ææ¨¡å—
# æ³¨æ„ï¼šæ–‡ä»¶åä¸­çš„æ•°å­—å¼€å¤´éœ€è¦ç‰¹æ®Šå¤„ç†
import importlib.util
import sys

def import_phi3_module():
    """åŠ¨æ€å¯¼å…¥ 5_intelligent_with_phi3.py æ¨¡å—"""
    spec = importlib.util.spec_from_file_location(
        "intelligent_with_phi3", 
        "5_intelligent_with_phi3.py"
    )
    module = importlib.util.module_from_spec(spec)
    sys.modules["intelligent_with_phi3"] = module
    spec.loader.exec_module(module)
    return module

try:
    phi3_module = import_phi3_module()
    PDFProcessor = phi3_module.PDFProcessor
    Phi3Analyzer = phi3_module.Phi3Analyzer
except Exception as e:
    print(f"âŒ æ— æ³•å¯¼å…¥åˆ†ææ¨¡å—: {e}")
    print("è¯·ç¡®ä¿ 5_intelligent_with_phi3.py æ–‡ä»¶å­˜åœ¨ä¸”æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    sys.exit(1)

def example_basic_usage():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ”¬ åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–ç»„ä»¶
    print("ğŸ“ æ­¥éª¤ 1: åˆå§‹åŒ–ç»„ä»¶")
    pdf_processor = PDFProcessor(download_dir="example_pdfs")
    phi3_analyzer = Phi3Analyzer()
    
    # 2. ç¤ºä¾‹æ–‡æœ¬åˆ†æï¼ˆä½¿ç”¨æ‘˜è¦æ–‡æœ¬ï¼‰
    print("\nğŸ“ æ­¥éª¤ 2: åˆ†æç¤ºä¾‹æ–‡æœ¬")
    sample_text = """
    This paper presents a novel approach to data-driven design for metamaterials 
    and multiscale systems. The research focuses on developing computational methods 
    that can automatically generate and optimize material structures based on desired 
    properties. The methodology combines machine learning algorithms with physics-based 
    simulations to create materials with unprecedented characteristics. The results 
    demonstrate significant improvements in material performance across various 
    applications including aerospace, automotive, and biomedical engineering.
    """
    
    # ç”Ÿæˆæ‘˜è¦
    print("ğŸ¤– ç”Ÿæˆ AI æ‘˜è¦...")
    summary = phi3_analyzer.generate_summary(sample_text)
    print(f"æ‘˜è¦: {summary}")
    
    # æå–å…³é”®è¯
    print("\nğŸ” æå–å…³é”®è¯...")
    keywords = phi3_analyzer.extract_keywords(sample_text)
    print(f"å…³é”®è¯: {', '.join(keywords)}")

def example_csv_processing():
    """å¤„ç† CSV æ–‡ä»¶ç¤ºä¾‹"""
    print("\n\nğŸ“Š CSV æ–‡ä»¶å¤„ç†ç¤ºä¾‹")
    print("=" * 50)
    
    csv_file = "output/merged_cleaned_results_intelligent_cleaned.csv"
    
    if not os.path.exists(csv_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_file}")
        print("è¯·ç¡®ä¿æ‚¨å·²ç»è¿è¡Œäº†å‰é¢çš„æ•°æ®æ”¶é›†æ­¥éª¤")
        return
    
    # è¯»å–æ•°æ®
    df = pd.read_csv(csv_file, encoding='utf-8')
    print(f"ğŸ“ˆ åŠ è½½äº† {len(df)} æ¡è®ºæ–‡è®°å½•")
    
    # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•çš„ä¿¡æ¯
    print("\nğŸ“‹ å‰ 3 æ¡è®°å½•çš„åŸºæœ¬ä¿¡æ¯:")
    for i, row in df.head(3).iterrows():
        print(f"\nè®ºæ–‡ {i+1}:")
        print(f"  æ ‡é¢˜: {row['title'][:80]}...")
        print(f"  ä½œè€…: {row['authors']}")
        print(f"  å¹´ä»½: {row['year']}")
        print(f"  å¼•ç”¨æ•°: {row['citations']}")
        if 'abstract' in row and pd.notna(row['abstract']):
            print(f"  æ‘˜è¦: {row['abstract'][:100]}...")

def example_single_paper_analysis():
    """å•ç¯‡è®ºæ–‡è¯¦ç»†åˆ†æç¤ºä¾‹"""
    print("\n\nğŸ” å•ç¯‡è®ºæ–‡è¯¦ç»†åˆ†æç¤ºä¾‹")
    print("=" * 50)
    
    csv_file = "output/merged_cleaned_results_intelligent_cleaned.csv"
    
    if not os.path.exists(csv_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_file}")
        return
    
    # è¯»å–æ•°æ®å¹¶é€‰æ‹©ä¸€ç¯‡è®ºæ–‡
    df = pd.read_csv(csv_file, encoding='utf-8')
    paper = df.iloc[0]  # é€‰æ‹©ç¬¬ä¸€ç¯‡è®ºæ–‡
    
    print(f"ğŸ“„ åˆ†æè®ºæ–‡: {paper['title']}")
    print(f"ğŸ‘¥ ä½œè€…: {paper['authors']}")
    print(f"ğŸ“… å¹´ä»½: {paper['year']}")
    print(f"ğŸ“Š å¼•ç”¨æ•°: {paper['citations']}")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    pdf_processor = PDFProcessor()
    phi3_analyzer = Phi3Analyzer()
    
    # ä½¿ç”¨æ‘˜è¦è¿›è¡Œåˆ†æï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    text_to_analyze = ""
    if 'abstract' in paper and pd.notna(paper['abstract']):
        text_to_analyze = paper['abstract']
        print(f"\nğŸ“ åŸå§‹æ‘˜è¦: {text_to_analyze}")
    
    # å¦‚æœæœ‰ URLï¼Œå°è¯•ä¸‹è½½ PDF
    if 'url' in paper and pd.notna(paper['url']):
        url = paper['url']
        print(f"\nğŸ”— è®ºæ–‡é“¾æ¥: {url}")
        
        # å¦‚æœ URL çœ‹èµ·æ¥åƒ PDFï¼Œå°è¯•ä¸‹è½½
        if 'pdf' in url.lower():
            print("ğŸ“¥ å°è¯•ä¸‹è½½ PDF...")
            pdf_path = pdf_processor.download_pdf(url, paper['title'])
            if pdf_path:
                print(f"âœ… PDF ä¸‹è½½æˆåŠŸ: {pdf_path}")
                
                # æå– PDF æ–‡æœ¬
                extracted_text = pdf_processor.extract_text_from_pdf(pdf_path)
                if extracted_text:
                    processed_text = pdf_processor.preprocess_text(extracted_text)
                    text_to_analyze = processed_text
                    print(f"ğŸ“„ PDF æ–‡æœ¬æå–æˆåŠŸï¼Œé•¿åº¦: {len(processed_text)} å­—ç¬¦")
            else:
                print("âŒ PDF ä¸‹è½½å¤±è´¥")
    
    # è¿›è¡Œ AI åˆ†æ
    if text_to_analyze:
        print("\nğŸ¤– ç”Ÿæˆ AI åˆ†æ...")
        
        # ç”Ÿæˆæ‘˜è¦
        ai_summary = phi3_analyzer.generate_summary(text_to_analyze)
        print(f"\nğŸ“‹ AI æ‘˜è¦:\n{ai_summary}")
        
        # æå–å…³é”®è¯
        keywords = phi3_analyzer.extract_keywords(text_to_analyze)
        print(f"\nğŸ·ï¸ å…³é”®è¯: {', '.join(keywords)}")
    else:
        print("\nâŒ æ²¡æœ‰å¯åˆ†æçš„æ–‡æœ¬å†…å®¹")

def example_batch_processing():
    """æ‰¹é‡å¤„ç†ç¤ºä¾‹"""
    print("\n\nâš¡ æ‰¹é‡å¤„ç†ç¤ºä¾‹")
    print("=" * 50)
    
    csv_file = "output/merged_cleaned_results_intelligent_cleaned.csv"
    
    if not os.path.exists(csv_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_file}")
        return
    
    # è¯»å–æ•°æ®
    df = pd.read_csv(csv_file, encoding='utf-8')
    
    # åªå¤„ç†å‰ 3 ç¯‡è®ºæ–‡ä½œä¸ºç¤ºä¾‹
    sample_papers = df.head(3)
    
    print(f"ğŸ“Š æ‰¹é‡å¤„ç† {len(sample_papers)} ç¯‡è®ºæ–‡...")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    phi3_analyzer = Phi3Analyzer()
    
    results = []
    
    for i, (idx, paper) in enumerate(sample_papers.iterrows()):
        print(f"\nğŸ“„ å¤„ç†è®ºæ–‡ {i+1}/{len(sample_papers)}: {paper['title'][:50]}...")
        
        # ä½¿ç”¨æ‘˜è¦è¿›è¡Œåˆ†æ
        text_to_analyze = ""
        if 'abstract' in paper and pd.notna(paper['abstract']):
            text_to_analyze = paper['abstract']
        
        if text_to_analyze:
            # ç”Ÿæˆæ‘˜è¦
            ai_summary = phi3_analyzer.generate_summary(text_to_analyze)
            
            # æå–å…³é”®è¯
            keywords = phi3_analyzer.extract_keywords(text_to_analyze)
            
            result = {
                'title': paper['title'],
                'original_abstract': text_to_analyze,
                'ai_summary': ai_summary,
                'keywords': ', '.join(keywords)
            }
            results.append(result)
            
            print(f"  âœ… å®Œæˆ")
        else:
            print(f"  âŒ è·³è¿‡ï¼ˆæ— æ‘˜è¦ï¼‰")
    
    # ä¿å­˜ç»“æœ
    if results:
        results_df = pd.DataFrame(results)
        output_file = "output/batch_analysis_results.csv"
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\nğŸ“‹ å¤„ç†ç»“æœæ‘˜è¦:")
        for i, result in enumerate(results):
            print(f"\nè®ºæ–‡ {i+1}: {result['title'][:60]}...")
            print(f"  AIæ‘˜è¦: {result['ai_summary'][:100]}...")
            print(f"  å…³é”®è¯: {result['keywords']}")

def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ Phi-3 è®ºæ–‡åˆ†æç³»ç»Ÿ - ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•
        Path("log").mkdir(exist_ok=True)
        Path("example_pdfs").mkdir(exist_ok=True)
        Path("output").mkdir(exist_ok=True)
        
        # è¿è¡Œç¤ºä¾‹
        example_basic_usage()
        example_csv_processing()
        example_single_paper_analysis()
        example_batch_processing()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\nğŸ’¡ æ¥ä¸‹æ¥æ‚¨å¯ä»¥ï¼š")
        print("  1. ä¿®æ”¹å‚æ•°æ¥é€‚åº”æ‚¨çš„éœ€æ±‚")
        print("  2. æ·»åŠ æ›´å¤šçš„åˆ†æåŠŸèƒ½")
        print("  3. é›†æˆåˆ°æ‚¨çš„å·¥ä½œæµç¨‹ä¸­")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
